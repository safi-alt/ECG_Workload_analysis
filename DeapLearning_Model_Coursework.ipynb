{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2292c6",
   "metadata": {},
   "source": [
    "Imports for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7529f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de9244",
   "metadata": {},
   "source": [
    "Load The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43df5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat(\"WLDataCW.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fbef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Fri Jan 21 21:10:34 2022',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'data': array([[[ 3.64516091e+00, -1.22507811e+00,  8.41415691e+00, ...,\n",
       "          -1.16731644e+01,  2.65084229e+01,  4.00945067e-01],\n",
       "         [ 1.57700694e+00,  2.68786597e+00,  2.37991428e+00, ...,\n",
       "          -9.80385399e+00,  2.95700607e+01,  1.86778176e+00],\n",
       "         [-2.88467383e+00,  3.47892046e+00, -3.33852053e+00, ...,\n",
       "          -7.33824921e+00,  3.09278240e+01,  2.78261375e+00],\n",
       "         ...,\n",
       "         [ 6.32441854e+00,  7.38758564e+00, -5.30264425e+00, ...,\n",
       "           2.92871971e+01, -2.80428171e-01, -4.32558784e+01],\n",
       "         [-5.14494121e-01,  1.25400152e+01, -2.38987041e+00, ...,\n",
       "           2.50036125e+01, -1.41281223e+00, -3.64643059e+01],\n",
       "         [-3.36245584e+00,  1.25796471e+01,  1.27706754e+00, ...,\n",
       "           2.42137814e+01, -1.03876221e+00, -3.15475597e+01]],\n",
       " \n",
       "        [[ 1.40172338e+01,  6.67675018e+00,  1.04504976e+01, ...,\n",
       "          -7.23842859e+00,  2.92477169e+01, -6.11521196e+00],\n",
       "         [ 9.57320786e+00,  1.03044224e+01,  4.34053040e+00, ...,\n",
       "          -4.79710388e+00,  3.15305920e+01, -7.08963251e+00],\n",
       "         [-7.80168712e-01,  1.05655098e+01, -5.22511229e-02, ...,\n",
       "          -2.61832881e+00,  3.26535683e+01, -7.25153923e+00],\n",
       "         ...,\n",
       "         [ 7.90308475e+00,  1.22880735e+01,  4.98843575e+00, ...,\n",
       "           3.23293724e+01, -6.49976206e+00,  5.57017365e+01],\n",
       "         [ 4.05146933e+00,  1.64621811e+01,  5.66283464e+00, ...,\n",
       "           2.92005520e+01, -5.72257710e+00,  5.68582687e+01],\n",
       "         [ 3.59683323e+00,  1.55021639e+01,  8.41522408e+00, ...,\n",
       "           2.80388393e+01, -5.46729231e+00,  5.88923912e+01]],\n",
       " \n",
       "        [[ 2.18900127e+01,  1.46132317e+01,  7.26650333e+00, ...,\n",
       "          -2.18015790e+00,  3.62625275e+01,  4.53556681e+00],\n",
       "         [ 1.79181061e+01,  2.59742088e+01,  2.93151569e+00, ...,\n",
       "          -1.08215618e+00,  4.24087029e+01, -2.04414868e+00],\n",
       "         [ 9.73524213e-01,  3.16501255e+01, -7.96142817e+00, ...,\n",
       "           7.11734593e-01,  4.39589424e+01, -7.86615849e+00],\n",
       "         ...,\n",
       "         [ 2.07960854e+01, -2.76862550e+00,  6.37866735e+00, ...,\n",
       "           3.14184742e+01,  6.56031466e+00, -6.39570236e+01],\n",
       "         [ 1.19519014e+01, -1.44232476e+00, -7.00410557e+00, ...,\n",
       "           2.80267296e+01,  9.29963779e+00, -7.50392761e+01],\n",
       "         [ 8.32365990e+00,  3.99110651e+00, -1.17747383e+01, ...,\n",
       "           3.00837345e+01,  8.77367115e+00, -8.04662399e+01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3.19179082e+00,  2.18730068e+01, -9.48453522e+00, ...,\n",
       "           2.93938708e+00,  1.42035639e+00, -5.10062790e+00],\n",
       "         [ 4.25754976e+00,  1.89893475e+01, -1.01470041e+01, ...,\n",
       "           4.93766642e+00,  2.68201947e-01, -5.10375166e+00],\n",
       "         [ 3.12493145e-01,  1.36081877e+01, -1.12219095e+01, ...,\n",
       "           6.34550953e+00, -1.00526929e+00, -6.45500660e+00],\n",
       "         ...,\n",
       "         [ 8.27328205e+00, -7.36880684e+00,  2.93866038e+00, ...,\n",
       "           6.48516130e+00, -4.77836037e+00, -4.75293770e+01],\n",
       "         [ 1.39407911e+01, -8.01225471e+00,  2.62550507e-02, ...,\n",
       "           4.87607861e+00, -5.66431141e+00, -3.94008598e+01],\n",
       "         [ 1.98325291e+01, -8.79270172e+00, -3.37120295e+00, ...,\n",
       "           2.96472096e+00, -5.63682985e+00, -3.40537415e+01]],\n",
       " \n",
       "        [[ 5.08650923e+00,  1.47223282e+01, -9.92165947e+00, ...,\n",
       "           4.33888865e+00,  6.59874201e+00,  3.38434410e+00],\n",
       "         [ 8.49818420e+00,  1.73258953e+01, -1.11496401e+01, ...,\n",
       "           3.54945922e+00,  3.64424872e+00,  2.35422277e+00],\n",
       "         [ 8.97051334e+00,  1.77623272e+01, -1.04793301e+01, ...,\n",
       "           9.78565216e-01,  1.33861160e+00, -8.25736299e-02],\n",
       "         ...,\n",
       "         [ 8.48828220e+00, -7.41737795e+00, -1.53939848e+01, ...,\n",
       "           9.39552975e+00,  1.00561345e+00, -6.89867096e+01],\n",
       "         [ 1.02233324e+01, -3.46780992e+00, -1.56789570e+01, ...,\n",
       "           9.97337627e+00,  2.13038230e+00, -5.34692688e+01],\n",
       "         [ 1.21313772e+01, -5.91963625e+00, -8.12416935e+00, ...,\n",
       "           9.01394463e+00,  3.06355262e+00, -3.44550819e+01]],\n",
       " \n",
       "        [[ 4.99157715e+00,  1.63893948e+01, -1.62950802e+01, ...,\n",
       "           9.07277107e+00,  4.79275131e+00, -6.08551204e-01],\n",
       "         [ 6.85308933e-01,  9.26526260e+00, -1.30421753e+01, ...,\n",
       "           8.58812332e+00,  1.47445035e+00, -3.16302598e-01],\n",
       "         [-4.40166759e+00,  3.62088704e+00, -1.49656515e+01, ...,\n",
       "           6.27468967e+00, -1.49104130e+00, -1.07978916e+00],\n",
       "         ...,\n",
       "         [ 6.51083899e+00, -2.61192474e+01, -1.88146305e+01, ...,\n",
       "           7.95619249e+00, -6.87760234e-01, -5.04130745e+01],\n",
       "         [ 1.26092758e+01, -2.67547798e+01, -2.07304039e+01, ...,\n",
       "           7.90902233e+00, -1.11071837e+00, -6.71540298e+01],\n",
       "         [ 1.78546543e+01, -2.22823448e+01, -1.12280722e+01, ...,\n",
       "           7.06333494e+00, -1.09680700e+00, -6.61702118e+01]]],\n",
       "       dtype=float32),\n",
       " 'label': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]], dtype=uint8)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee984793",
   "metadata": {},
   "source": [
    "Pre process and Reshape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2188e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0c398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 512, 360)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d6db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95846d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 512, 62)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d81e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24460840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 360)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3feeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.transpose(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd738d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e3022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3f4815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c3e7371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842155c5",
   "metadata": {},
   "source": [
    "Applying Standard Scaler to convert data values into standard values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dac7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_transform = scaler.fit_transform(X.reshape(-1,X.shape[-1])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6bcdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 512, 62)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca065ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.61168098e-01,  6.91580951e-01,  1.01101410e+00, ...,\n",
       "          3.63649577e-01,  4.69384611e-01,  4.90507603e-01],\n",
       "        [ 6.83511198e-02,  4.72435027e-01,  8.26347291e-01, ...,\n",
       "          4.88638610e-01,  7.89436162e-01,  6.16748370e-02],\n",
       "        [-1.31885305e-01, -3.81155685e-02,  3.85388657e-02, ...,\n",
       "          2.59739589e-02,  8.33745658e-01, -4.44903523e-01],\n",
       "        ...,\n",
       "        [ 2.81410903e-01,  3.90077144e-01,  9.60153878e-01, ...,\n",
       "          9.59591985e-01,  7.88507223e-01,  6.41800880e-01],\n",
       "        [-2.55136658e-02,  2.00144455e-01,  5.48959196e-01, ...,\n",
       "          1.62426090e+00,  9.51273441e-01,  1.24910390e+00],\n",
       "        [-1.53327763e-01,  1.77725226e-01,  3.80270481e-01, ...,\n",
       "          2.31522655e+00,  1.13026845e+00,  1.77145636e+00]],\n",
       "\n",
       "       [[-5.74040674e-02,  3.29603553e-01,  6.72693014e-01, ...,\n",
       "          2.55452776e+00,  1.37332726e+00,  1.62554085e+00],\n",
       "        [ 1.18205525e-01,  5.08493066e-01,  1.20090163e+00, ...,\n",
       "          2.21634078e+00,  1.61756957e+00,  9.16095734e-01],\n",
       "        [ 1.53707370e-01,  5.21367908e-01,  1.46479332e+00, ...,\n",
       "          1.58525407e+00,  1.65851152e+00,  3.54009658e-01],\n",
       "        ...,\n",
       "        [ 3.29124928e-01,  6.06311798e-01, -1.35445789e-01, ...,\n",
       "         -8.74866426e-01, -7.03613341e-01, -2.60761380e+00],\n",
       "        [ 5.60361564e-01,  8.12147379e-01, -7.37817734e-02, ...,\n",
       "         -9.50328052e-01, -3.33101720e-01, -2.67090225e+00],\n",
       "        [ 5.62140226e-01,  7.64806509e-01,  1.78836033e-01, ...,\n",
       "         -1.04185665e+00, -5.63109219e-01, -2.22552204e+00]],\n",
       "\n",
       "       [[ 3.75196576e-01,  5.15696347e-01,  3.31119835e-01, ...,\n",
       "         -1.12299287e+00, -9.38541651e-01, -1.62928987e+00],\n",
       "        [ 1.04384914e-01,  2.14398772e-01,  1.29572228e-01, ...,\n",
       "         -1.20068526e+00, -1.05373931e+00, -1.30535448e+00],\n",
       "        [-1.52253553e-01, -2.22015125e-03, -3.76875997e-01, ...,\n",
       "         -1.32674694e+00, -9.90857065e-01, -1.49690080e+00],\n",
       "        ...,\n",
       "        [-2.40401745e-01,  2.46348590e-01,  2.89841473e-01, ...,\n",
       "          3.33963156e-01, -1.45190406e+00, -1.88019526e+00],\n",
       "        [-1.09678954e-01,  2.79604852e-01, -3.32366973e-01, ...,\n",
       "         -7.59520661e-03, -1.47863758e+00, -2.07097459e+00],\n",
       "        [ 5.48900925e-02,  4.15331990e-01, -5.54169118e-01, ...,\n",
       "         -4.06039119e-01, -7.69917905e-01, -1.12469995e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-5.26305258e-01, -3.56588364e-01, -1.08086027e-01, ...,\n",
       "          3.34048390e-01,  3.99249822e-01,  8.96926761e-01],\n",
       "        [-4.42412198e-01, -2.36200586e-01, -5.70363700e-02, ...,\n",
       "          5.68400741e-01,  3.25192958e-01,  8.48663926e-01],\n",
       "        [-3.31757963e-01, -1.28759786e-01,  2.63674203e-02, ...,\n",
       "          7.33508408e-01,  8.40156674e-02,  6.18284285e-01],\n",
       "        ...,\n",
       "        [ 1.31196082e+00,  1.59459782e+00,  1.45402312e+00, ...,\n",
       "          7.49886394e-01,  8.73616755e-01,  7.85734057e-01],\n",
       "        [ 1.11971724e+00,  1.44030797e+00,  1.29632998e+00, ...,\n",
       "          5.61177850e-01,  9.27824914e-01,  7.81036675e-01],\n",
       "        [ 1.08427024e+00,  1.38302100e+00,  1.39196670e+00, ...,\n",
       "          3.37019473e-01,  8.37819993e-01,  6.96820259e-01]],\n",
       "\n",
       "       [[ 1.18725181e+00,  1.44263375e+00,  1.67923880e+00, ...,\n",
       "          1.55900925e-01,  6.11248195e-01,  4.70707864e-01],\n",
       "        [ 1.32465553e+00,  1.55520797e+00,  1.96499443e+00, ...,\n",
       "          2.07796171e-02,  3.34085226e-01,  1.40260205e-01],\n",
       "        [ 1.38559079e+00,  1.61058474e+00,  2.03707004e+00, ...,\n",
       "         -1.28569365e-01,  1.17791854e-01, -1.55053496e-01],\n",
       "        ...,\n",
       "        [-1.50089860e-02, -3.20162892e-01,  2.98286825e-01, ...,\n",
       "         -5.71066439e-01,  8.65530819e-02, -7.50600472e-02],\n",
       "        [-6.58294186e-02, -2.81837970e-01,  4.25646842e-01, ...,\n",
       "         -6.74968183e-01,  1.92068398e-01, -1.17179655e-01],\n",
       "        [-4.90423702e-02, -2.69249231e-01,  4.01192963e-01, ...,\n",
       "         -6.71745241e-01,  2.79609740e-01, -1.15794316e-01]],\n",
       "\n",
       "       [[ 1.55704636e-02, -3.01199764e-01,  2.04149753e-01, ...,\n",
       "         -6.08861029e-01,  3.09703380e-01, -6.71721399e-02],\n",
       "        [ 8.14008415e-02, -3.49250853e-01, -1.01762518e-01, ...,\n",
       "         -6.09227419e-01,  2.13067025e-01, -3.80690359e-02],\n",
       "        [ 1.22457720e-01, -3.57234865e-01, -3.72446567e-01, ...,\n",
       "         -7.67698646e-01, -1.55304726e-02, -1.14099622e-01],\n",
       "        ...,\n",
       "        [-1.94371057e+00,  2.74714684e+00, -2.98029232e+00, ...,\n",
       "         -5.58478069e+00, -6.47947311e+00, -5.02687502e+00],\n",
       "        [-1.63891065e+00,  2.80417848e+00, -3.49554205e+00, ...,\n",
       "         -4.63149166e+00, -5.02377176e+00, -6.69399643e+00],\n",
       "        [-1.41825116e+00,  2.90448594e+00, -3.74785924e+00, ...,\n",
       "         -4.00439739e+00, -3.24003839e+00, -6.59602451e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76efbd48",
   "metadata": {},
   "source": [
    "Splitting data into train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e3ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,Y_train,Y_test=train_test_split(X_transform,y, test_size=0.22,random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1020e",
   "metadata": {},
   "source": [
    "Initialize CNN Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "741225bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \n",
    "    model= keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=5,kernel_size=3,strides=1,input_shape=(512,62))) #1\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.MaxPool1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=5,kernel_size=3,strides=1)) #2\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.MaxPool1D(pool_size=2, strides=2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=5,kernel_size=3,strides=1)) #3\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.AveragePooling1D(pool_size=2, strides=2))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=5,kernel_size=3,strides=1)) #4\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.AveragePooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(layers.Conv1D(filters=5,kernel_size=3,strides=1)) #5\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58927250",
   "metadata": {},
   "source": [
    "Summary of the Above CNN architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c694179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 510, 5)            935       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 510, 5)           20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 510, 5)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 255, 5)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 253, 5)            80        \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 253, 5)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 126, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 126, 5)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 124, 5)            80        \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 124, 5)            0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 62, 5)            0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 62, 5)             0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 60, 5)             80        \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 60, 5)             0         \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (None, 30, 5)            0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 28, 5)             80        \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 28, 5)             0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 5)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               768       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,172\n",
      "Trainable params: 2,162\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 05:43:27.351091: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "init_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64f34d",
   "metadata": {},
   "source": [
    "Applying StandardScaler with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b617ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "344cbc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 512, 62)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b405045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677cfd1",
   "metadata": {},
   "source": [
    "Validation Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac732872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.6945 - accuracy: 0.4688 - val_loss: 0.6947 - val_accuracy: 0.4821\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6932 - accuracy: 0.5268 - val_loss: 0.6939 - val_accuracy: 0.4643\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6912 - accuracy: 0.5804 - val_loss: 0.6928 - val_accuracy: 0.5179\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6905 - accuracy: 0.5848 - val_loss: 0.6928 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6878 - accuracy: 0.6875 - val_loss: 0.6930 - val_accuracy: 0.5893\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6871 - accuracy: 0.6786 - val_loss: 0.6924 - val_accuracy: 0.6250\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6848 - accuracy: 0.6295 - val_loss: 0.6897 - val_accuracy: 0.7143\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6792 - accuracy: 0.6116 - val_loss: 0.6893 - val_accuracy: 0.6786\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6759 - accuracy: 0.6429 - val_loss: 0.6878 - val_accuracy: 0.6786\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6706 - accuracy: 0.6429 - val_loss: 0.6857 - val_accuracy: 0.7143\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6672 - accuracy: 0.6205 - val_loss: 0.6853 - val_accuracy: 0.7143\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6577 - accuracy: 0.6830 - val_loss: 0.6831 - val_accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6469 - accuracy: 0.7455 - val_loss: 0.6808 - val_accuracy: 0.6964\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6330 - accuracy: 0.7589 - val_loss: 0.6725 - val_accuracy: 0.7321\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6158 - accuracy: 0.7143 - val_loss: 0.6644 - val_accuracy: 0.7143\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5916 - accuracy: 0.7500 - val_loss: 0.6599 - val_accuracy: 0.8036\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5853 - accuracy: 0.7679 - val_loss: 0.6537 - val_accuracy: 0.7679\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5611 - accuracy: 0.8259 - val_loss: 0.6469 - val_accuracy: 0.7679\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5433 - accuracy: 0.8259 - val_loss: 0.6537 - val_accuracy: 0.7857\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5150 - accuracy: 0.8661 - val_loss: 0.6460 - val_accuracy: 0.7857\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4881 - accuracy: 0.8839 - val_loss: 0.6357 - val_accuracy: 0.8036\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4741 - accuracy: 0.8705 - val_loss: 0.6321 - val_accuracy: 0.7857\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4715 - accuracy: 0.8393 - val_loss: 0.6777 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4153 - accuracy: 0.8884 - val_loss: 0.7009 - val_accuracy: 0.7857\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4285 - accuracy: 0.8527 - val_loss: 0.6750 - val_accuracy: 0.8036\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3959 - accuracy: 0.8705 - val_loss: 0.6655 - val_accuracy: 0.8036\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3819 - accuracy: 0.8661 - val_loss: 0.6649 - val_accuracy: 0.8393\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3799 - accuracy: 0.8750 - val_loss: 0.6894 - val_accuracy: 0.8036\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3395 - accuracy: 0.8705 - val_loss: 0.6911 - val_accuracy: 0.8036\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3234 - accuracy: 0.8661 - val_loss: 0.6550 - val_accuracy: 0.8214\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3393 - accuracy: 0.8571 - val_loss: 0.6704 - val_accuracy: 0.8214\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2980 - accuracy: 0.9062 - val_loss: 0.6757 - val_accuracy: 0.8393\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3063 - accuracy: 0.8973 - val_loss: 0.6919 - val_accuracy: 0.8393\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2906 - accuracy: 0.8973 - val_loss: 0.6999 - val_accuracy: 0.8214\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2655 - accuracy: 0.9018 - val_loss: 0.7431 - val_accuracy: 0.8214\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2872 - accuracy: 0.8839 - val_loss: 0.7431 - val_accuracy: 0.8214\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2887 - accuracy: 0.9196 - val_loss: 0.7477 - val_accuracy: 0.8393\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2149 - accuracy: 0.9420 - val_loss: 0.6979 - val_accuracy: 0.8393\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2592 - accuracy: 0.8973 - val_loss: 0.6955 - val_accuracy: 0.8214\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2662 - accuracy: 0.8884 - val_loss: 0.6318 - val_accuracy: 0.8214\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2523 - accuracy: 0.8929 - val_loss: 0.6204 - val_accuracy: 0.8929\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2641 - accuracy: 0.8929 - val_loss: 0.6126 - val_accuracy: 0.8571\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2593 - accuracy: 0.9107 - val_loss: 0.5867 - val_accuracy: 0.8571\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2451 - accuracy: 0.9196 - val_loss: 0.5628 - val_accuracy: 0.8571\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2066 - accuracy: 0.9330 - val_loss: 0.5844 - val_accuracy: 0.8929\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2443 - accuracy: 0.9062 - val_loss: 0.6209 - val_accuracy: 0.8750\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2366 - accuracy: 0.8973 - val_loss: 0.7000 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2642 - accuracy: 0.9062 - val_loss: 0.6169 - val_accuracy: 0.8929\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2459 - accuracy: 0.9152 - val_loss: 0.5614 - val_accuracy: 0.8929\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2098 - accuracy: 0.9375 - val_loss: 0.5340 - val_accuracy: 0.9107\n",
      "[0.9107142686843872]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 86ms/step - loss: 0.6941 - accuracy: 0.5134 - val_loss: 0.6925 - val_accuracy: 0.6786\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6920 - accuracy: 0.5536 - val_loss: 0.6922 - val_accuracy: 0.6071\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6923 - accuracy: 0.5580 - val_loss: 0.6917 - val_accuracy: 0.5714\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6907 - accuracy: 0.5714 - val_loss: 0.6905 - val_accuracy: 0.6607\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6903 - accuracy: 0.6562 - val_loss: 0.6900 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6885 - accuracy: 0.6384 - val_loss: 0.6906 - val_accuracy: 0.5536\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6872 - accuracy: 0.6518 - val_loss: 0.6898 - val_accuracy: 0.5893\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6875 - accuracy: 0.6339 - val_loss: 0.6886 - val_accuracy: 0.5893\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6855 - accuracy: 0.6161 - val_loss: 0.6877 - val_accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6816 - accuracy: 0.6518 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6783 - accuracy: 0.7098 - val_loss: 0.6825 - val_accuracy: 0.5893\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6752 - accuracy: 0.7054 - val_loss: 0.6762 - val_accuracy: 0.5893\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6671 - accuracy: 0.7143 - val_loss: 0.6724 - val_accuracy: 0.5893\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6601 - accuracy: 0.7545 - val_loss: 0.6658 - val_accuracy: 0.5714\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6476 - accuracy: 0.7545 - val_loss: 0.6510 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6379 - accuracy: 0.7902 - val_loss: 0.6358 - val_accuracy: 0.7321\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6068 - accuracy: 0.8125 - val_loss: 0.6260 - val_accuracy: 0.7143\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5887 - accuracy: 0.8304 - val_loss: 0.6134 - val_accuracy: 0.7321\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5768 - accuracy: 0.7946 - val_loss: 0.5971 - val_accuracy: 0.7143\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5287 - accuracy: 0.8438 - val_loss: 0.5842 - val_accuracy: 0.6964\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5141 - accuracy: 0.8214 - val_loss: 0.5717 - val_accuracy: 0.7143\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5010 - accuracy: 0.8214 - val_loss: 0.5568 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4466 - accuracy: 0.8571 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4031 - accuracy: 0.8705 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3798 - accuracy: 0.8750 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3669 - accuracy: 0.8705 - val_loss: 0.5231 - val_accuracy: 0.7679\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3811 - accuracy: 0.8705 - val_loss: 0.4931 - val_accuracy: 0.7857\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3202 - accuracy: 0.8929 - val_loss: 0.5010 - val_accuracy: 0.7679\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3008 - accuracy: 0.9062 - val_loss: 0.4760 - val_accuracy: 0.8214\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3028 - accuracy: 0.8839 - val_loss: 0.5112 - val_accuracy: 0.7679\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2630 - accuracy: 0.9107 - val_loss: 0.4933 - val_accuracy: 0.7857\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2669 - accuracy: 0.9196 - val_loss: 0.5153 - val_accuracy: 0.8214\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2837 - accuracy: 0.9107 - val_loss: 0.5012 - val_accuracy: 0.8214\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2608 - accuracy: 0.9152 - val_loss: 0.5150 - val_accuracy: 0.8214\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2575 - accuracy: 0.9330 - val_loss: 0.4928 - val_accuracy: 0.8214\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2545 - accuracy: 0.9196 - val_loss: 0.4839 - val_accuracy: 0.8214\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2427 - accuracy: 0.9420 - val_loss: 0.4829 - val_accuracy: 0.8036\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2219 - accuracy: 0.9554 - val_loss: 0.4851 - val_accuracy: 0.8036\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2184 - accuracy: 0.9375 - val_loss: 0.4846 - val_accuracy: 0.8036\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2159 - accuracy: 0.9375 - val_loss: 0.4953 - val_accuracy: 0.8214\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1997 - accuracy: 0.9420 - val_loss: 0.5129 - val_accuracy: 0.8214\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2057 - accuracy: 0.9286 - val_loss: 0.5140 - val_accuracy: 0.8214\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2159 - accuracy: 0.9196 - val_loss: 0.4857 - val_accuracy: 0.8571\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2170 - accuracy: 0.9375 - val_loss: 0.4949 - val_accuracy: 0.8393\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1833 - accuracy: 0.9554 - val_loss: 0.5029 - val_accuracy: 0.8214\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1831 - accuracy: 0.9152 - val_loss: 0.4883 - val_accuracy: 0.8214\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1730 - accuracy: 0.9420 - val_loss: 0.4771 - val_accuracy: 0.8393\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2016 - accuracy: 0.9509 - val_loss: 0.4813 - val_accuracy: 0.8214\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1738 - accuracy: 0.9420 - val_loss: 0.5054 - val_accuracy: 0.8214\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1685 - accuracy: 0.9554 - val_loss: 0.5228 - val_accuracy: 0.8214\n",
      "[0.9107142686843872, 0.8214285969734192]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 88ms/step - loss: 0.6884 - accuracy: 0.5134 - val_loss: 0.6996 - val_accuracy: 0.3571\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6827 - accuracy: 0.5134 - val_loss: 0.6924 - val_accuracy: 0.3571\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6768 - accuracy: 0.5134 - val_loss: 0.6892 - val_accuracy: 0.3571\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6684 - accuracy: 0.5134 - val_loss: 0.6831 - val_accuracy: 0.3571\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6582 - accuracy: 0.5134 - val_loss: 0.6749 - val_accuracy: 0.3750\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6500 - accuracy: 0.5134 - val_loss: 0.6642 - val_accuracy: 0.4286\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6432 - accuracy: 0.5134 - val_loss: 0.6510 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6318 - accuracy: 0.5134 - val_loss: 0.6368 - val_accuracy: 0.6429\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6159 - accuracy: 0.5357 - val_loss: 0.6217 - val_accuracy: 0.8393\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5990 - accuracy: 0.5759 - val_loss: 0.6041 - val_accuracy: 0.8571\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5979 - accuracy: 0.5938 - val_loss: 0.5861 - val_accuracy: 0.9107\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5778 - accuracy: 0.6875 - val_loss: 0.5751 - val_accuracy: 0.9464\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5607 - accuracy: 0.7902 - val_loss: 0.5629 - val_accuracy: 0.9286\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5519 - accuracy: 0.8214 - val_loss: 0.5434 - val_accuracy: 0.9286\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5370 - accuracy: 0.8438 - val_loss: 0.5260 - val_accuracy: 0.9286\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5315 - accuracy: 0.8527 - val_loss: 0.5211 - val_accuracy: 0.9286\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5054 - accuracy: 0.8661 - val_loss: 0.5071 - val_accuracy: 0.9107\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5051 - accuracy: 0.8929 - val_loss: 0.4929 - val_accuracy: 0.9107\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4965 - accuracy: 0.8929 - val_loss: 0.4747 - val_accuracy: 0.9464\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4779 - accuracy: 0.9062 - val_loss: 0.4533 - val_accuracy: 0.9286\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4546 - accuracy: 0.8973 - val_loss: 0.4415 - val_accuracy: 0.9464\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4446 - accuracy: 0.8839 - val_loss: 0.4370 - val_accuracy: 0.9286\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4315 - accuracy: 0.8973 - val_loss: 0.4327 - val_accuracy: 0.9286\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4089 - accuracy: 0.8973 - val_loss: 0.4202 - val_accuracy: 0.9107\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4031 - accuracy: 0.9062 - val_loss: 0.3913 - val_accuracy: 0.9107\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3988 - accuracy: 0.9018 - val_loss: 0.3714 - val_accuracy: 0.9464\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3809 - accuracy: 0.9107 - val_loss: 0.3592 - val_accuracy: 0.9286\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3705 - accuracy: 0.9062 - val_loss: 0.3428 - val_accuracy: 0.9286\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3646 - accuracy: 0.8884 - val_loss: 0.3314 - val_accuracy: 0.9107\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3455 - accuracy: 0.9196 - val_loss: 0.3231 - val_accuracy: 0.9286\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3367 - accuracy: 0.8973 - val_loss: 0.2976 - val_accuracy: 0.9286\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3521 - accuracy: 0.8929 - val_loss: 0.2685 - val_accuracy: 0.9107\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2993 - accuracy: 0.9152 - val_loss: 0.2707 - val_accuracy: 0.9286\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3140 - accuracy: 0.9062 - val_loss: 0.2563 - val_accuracy: 0.9286\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2960 - accuracy: 0.9152 - val_loss: 0.2450 - val_accuracy: 0.9286\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2832 - accuracy: 0.9330 - val_loss: 0.2327 - val_accuracy: 0.9464\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2665 - accuracy: 0.9107 - val_loss: 0.2220 - val_accuracy: 0.9464\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2610 - accuracy: 0.9330 - val_loss: 0.2253 - val_accuracy: 0.9464\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2773 - accuracy: 0.9152 - val_loss: 0.2412 - val_accuracy: 0.9107\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2651 - accuracy: 0.9107 - val_loss: 0.2331 - val_accuracy: 0.9286\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2340 - accuracy: 0.9375 - val_loss: 0.2218 - val_accuracy: 0.9107\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2101 - accuracy: 0.9330 - val_loss: 0.2322 - val_accuracy: 0.9286\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2394 - accuracy: 0.9241 - val_loss: 0.2046 - val_accuracy: 0.9643\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2327 - accuracy: 0.9241 - val_loss: 0.2002 - val_accuracy: 0.9464\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2189 - accuracy: 0.9330 - val_loss: 0.2024 - val_accuracy: 0.9464\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2305 - accuracy: 0.9375 - val_loss: 0.1972 - val_accuracy: 0.9464\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2404 - accuracy: 0.9375 - val_loss: 0.1909 - val_accuracy: 0.9464\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2089 - accuracy: 0.9420 - val_loss: 0.2003 - val_accuracy: 0.9464\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2196 - accuracy: 0.9196 - val_loss: 0.2114 - val_accuracy: 0.9464\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1880 - accuracy: 0.9420 - val_loss: 0.1836 - val_accuracy: 0.9464\n",
      "[0.9107142686843872, 0.8214285969734192, 0.9464285969734192]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 88ms/step - loss: 0.6932 - accuracy: 0.4643 - val_loss: 0.6902 - val_accuracy: 0.6786\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6911 - accuracy: 0.5759 - val_loss: 0.6909 - val_accuracy: 0.6607\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6897 - val_accuracy: 0.6429\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6874 - accuracy: 0.7321 - val_loss: 0.6879 - val_accuracy: 0.6786\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6842 - accuracy: 0.7679 - val_loss: 0.6852 - val_accuracy: 0.7143\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6814 - accuracy: 0.7188 - val_loss: 0.6810 - val_accuracy: 0.7857\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6778 - accuracy: 0.6741 - val_loss: 0.6756 - val_accuracy: 0.7857\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6713 - accuracy: 0.6696 - val_loss: 0.6685 - val_accuracy: 0.8036\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6624 - accuracy: 0.6295 - val_loss: 0.6587 - val_accuracy: 0.7857\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6547 - accuracy: 0.6384 - val_loss: 0.6459 - val_accuracy: 0.8214\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6435 - accuracy: 0.6607 - val_loss: 0.6296 - val_accuracy: 0.8393\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6252 - accuracy: 0.6964 - val_loss: 0.6139 - val_accuracy: 0.8571\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6144 - accuracy: 0.7500 - val_loss: 0.5950 - val_accuracy: 0.8393\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5936 - accuracy: 0.8036 - val_loss: 0.5779 - val_accuracy: 0.8393\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5752 - accuracy: 0.8393 - val_loss: 0.5612 - val_accuracy: 0.8393\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5619 - accuracy: 0.8527 - val_loss: 0.5440 - val_accuracy: 0.8393\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5365 - accuracy: 0.8750 - val_loss: 0.5280 - val_accuracy: 0.8571\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5218 - accuracy: 0.8929 - val_loss: 0.5195 - val_accuracy: 0.8750\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5074 - accuracy: 0.8839 - val_loss: 0.5103 - val_accuracy: 0.8750\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4855 - accuracy: 0.8839 - val_loss: 0.5000 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4728 - accuracy: 0.8884 - val_loss: 0.4897 - val_accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4608 - accuracy: 0.8929 - val_loss: 0.4781 - val_accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4271 - accuracy: 0.8839 - val_loss: 0.4651 - val_accuracy: 0.8571\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4196 - accuracy: 0.8795 - val_loss: 0.4532 - val_accuracy: 0.8571\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4053 - accuracy: 0.8750 - val_loss: 0.4455 - val_accuracy: 0.8750\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4035 - accuracy: 0.8884 - val_loss: 0.4460 - val_accuracy: 0.8750\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3916 - accuracy: 0.8705 - val_loss: 0.4345 - val_accuracy: 0.8750\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3569 - accuracy: 0.8795 - val_loss: 0.4255 - val_accuracy: 0.8750\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3344 - accuracy: 0.8929 - val_loss: 0.4076 - val_accuracy: 0.9107\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3220 - accuracy: 0.8884 - val_loss: 0.3952 - val_accuracy: 0.8929\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3073 - accuracy: 0.8795 - val_loss: 0.3941 - val_accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2883 - accuracy: 0.8884 - val_loss: 0.3932 - val_accuracy: 0.8571\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2802 - accuracy: 0.8929 - val_loss: 0.3887 - val_accuracy: 0.8750\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2593 - accuracy: 0.9107 - val_loss: 0.3835 - val_accuracy: 0.8750\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2680 - accuracy: 0.9062 - val_loss: 0.3831 - val_accuracy: 0.8929\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2597 - accuracy: 0.9107 - val_loss: 0.3860 - val_accuracy: 0.8929\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2262 - accuracy: 0.9286 - val_loss: 0.3919 - val_accuracy: 0.8929\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2506 - accuracy: 0.9196 - val_loss: 0.3679 - val_accuracy: 0.8750\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2055 - accuracy: 0.9330 - val_loss: 0.3585 - val_accuracy: 0.8929\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2236 - accuracy: 0.9330 - val_loss: 0.3693 - val_accuracy: 0.8929\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2366 - accuracy: 0.9062 - val_loss: 0.3664 - val_accuracy: 0.8929\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1988 - accuracy: 0.9420 - val_loss: 0.3669 - val_accuracy: 0.8750\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2059 - accuracy: 0.9286 - val_loss: 0.3568 - val_accuracy: 0.8750\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1748 - accuracy: 0.9330 - val_loss: 0.3553 - val_accuracy: 0.9107\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1986 - accuracy: 0.9464 - val_loss: 0.3781 - val_accuracy: 0.8929\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1716 - accuracy: 0.9554 - val_loss: 0.3563 - val_accuracy: 0.9107\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1876 - accuracy: 0.9509 - val_loss: 0.3596 - val_accuracy: 0.8929\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1742 - accuracy: 0.9554 - val_loss: 0.3817 - val_accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1584 - accuracy: 0.9554 - val_loss: 0.3622 - val_accuracy: 0.8929\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1703 - accuracy: 0.9420 - val_loss: 0.3560 - val_accuracy: 0.8929\n",
      "[0.9107142686843872, 0.8214285969734192, 0.9464285969734192, 0.8928571343421936]\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 87ms/step - loss: 0.6939 - accuracy: 0.4688 - val_loss: 0.6921 - val_accuracy: 0.6071\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6927 - accuracy: 0.5223 - val_loss: 0.6925 - val_accuracy: 0.4643\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6914 - accuracy: 0.5312 - val_loss: 0.6932 - val_accuracy: 0.4821\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6912 - accuracy: 0.5312 - val_loss: 0.6939 - val_accuracy: 0.4643\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6906 - accuracy: 0.5312 - val_loss: 0.6938 - val_accuracy: 0.4643\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6904 - accuracy: 0.5268 - val_loss: 0.6934 - val_accuracy: 0.4643\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6885 - accuracy: 0.5312 - val_loss: 0.6932 - val_accuracy: 0.4643\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6860 - accuracy: 0.5312 - val_loss: 0.6921 - val_accuracy: 0.4643\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6835 - accuracy: 0.5268 - val_loss: 0.6898 - val_accuracy: 0.4643\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6807 - accuracy: 0.5446 - val_loss: 0.6853 - val_accuracy: 0.4643\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6753 - accuracy: 0.6295 - val_loss: 0.6817 - val_accuracy: 0.5357\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6679 - accuracy: 0.7143 - val_loss: 0.6748 - val_accuracy: 0.6071\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6552 - accuracy: 0.8036 - val_loss: 0.6648 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6452 - accuracy: 0.8125 - val_loss: 0.6510 - val_accuracy: 0.7321\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6232 - accuracy: 0.8482 - val_loss: 0.6381 - val_accuracy: 0.7321\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5975 - accuracy: 0.8839 - val_loss: 0.6153 - val_accuracy: 0.7143\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5773 - accuracy: 0.8571 - val_loss: 0.5871 - val_accuracy: 0.7321\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5443 - accuracy: 0.8705 - val_loss: 0.5599 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5030 - accuracy: 0.8750 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4681 - accuracy: 0.8616 - val_loss: 0.5056 - val_accuracy: 0.7679\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4275 - accuracy: 0.8750 - val_loss: 0.4542 - val_accuracy: 0.8393\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4004 - accuracy: 0.8839 - val_loss: 0.4500 - val_accuracy: 0.8393\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3419 - accuracy: 0.9241 - val_loss: 0.4360 - val_accuracy: 0.8214\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.3254 - accuracy: 0.9241 - val_loss: 0.4194 - val_accuracy: 0.8393\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2999 - accuracy: 0.9018 - val_loss: 0.3922 - val_accuracy: 0.8571\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2662 - accuracy: 0.9286 - val_loss: 0.3799 - val_accuracy: 0.8750\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2547 - accuracy: 0.9330 - val_loss: 0.3802 - val_accuracy: 0.8750\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2611 - accuracy: 0.9152 - val_loss: 0.3671 - val_accuracy: 0.8929\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2045 - accuracy: 0.9464 - val_loss: 0.3588 - val_accuracy: 0.8929\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2202 - accuracy: 0.9464 - val_loss: 0.3767 - val_accuracy: 0.8750\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2020 - accuracy: 0.9330 - val_loss: 0.3999 - val_accuracy: 0.8571\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2276 - accuracy: 0.8929 - val_loss: 0.3996 - val_accuracy: 0.8929\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1901 - accuracy: 0.9509 - val_loss: 0.4043 - val_accuracy: 0.9286\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2096 - accuracy: 0.9330 - val_loss: 0.4102 - val_accuracy: 0.8929\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1878 - accuracy: 0.9464 - val_loss: 0.4158 - val_accuracy: 0.8929\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1606 - accuracy: 0.9598 - val_loss: 0.4126 - val_accuracy: 0.8929\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1902 - accuracy: 0.9598 - val_loss: 0.4059 - val_accuracy: 0.9107\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1702 - accuracy: 0.9554 - val_loss: 0.4023 - val_accuracy: 0.9286\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1931 - accuracy: 0.9464 - val_loss: 0.4045 - val_accuracy: 0.9286\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1471 - accuracy: 0.9643 - val_loss: 0.4086 - val_accuracy: 0.9286\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1371 - accuracy: 0.9777 - val_loss: 0.4100 - val_accuracy: 0.9286\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1401 - accuracy: 0.9777 - val_loss: 0.4161 - val_accuracy: 0.9107\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1728 - accuracy: 0.9286 - val_loss: 0.4186 - val_accuracy: 0.9286\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1495 - accuracy: 0.9598 - val_loss: 0.4332 - val_accuracy: 0.9286\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1302 - accuracy: 0.9688 - val_loss: 0.4259 - val_accuracy: 0.9286\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1273 - accuracy: 0.9598 - val_loss: 0.4167 - val_accuracy: 0.9286\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1487 - accuracy: 0.9554 - val_loss: 0.4136 - val_accuracy: 0.9286\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1404 - accuracy: 0.9598 - val_loss: 0.4187 - val_accuracy: 0.9286\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1425 - accuracy: 0.9643 - val_loss: 0.4311 - val_accuracy: 0.9286\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1297 - accuracy: 0.9732 - val_loss: 0.4555 - val_accuracy: 0.9107\n",
      "[0.9107142686843872, 0.8214285969734192, 0.9464285969734192, 0.8928571343421936, 0.9107142686843872]\n"
     ]
    }
   ],
   "source": [
    "val_accuracy=[]\n",
    "accuracy=[]\n",
    "for train_index, test_index in kf.split(x_train, Y_train):\n",
    "    X_train, X_test = x_train[train_index], x_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "#     scaler=StandardScaler()\n",
    "    \n",
    "#     X_train = scaler.fit_transform(X_train.reshape(-1,X_train.shape[-1])).reshape(X_train.shape)\n",
    "#     X_test = scaler.fit_transform(X_test.reshape(-1,X_test.shape[-1])).reshape(X_test.shape)\n",
    "    \n",
    "    history = init_model().fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n",
    "    val_accuracy.append(history.history['val_accuracy'][len(history.history['val_accuracy'])-1])\n",
    "    print(val_accuracy)\n",
    "#     accuracy.append(model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e3255d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964285731315613"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c6fb0",
   "metadata": {},
   "source": [
    "Calculation of validation Accuracy using CNN architecture and EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "667ef449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 76ms/step - loss: 0.6936 - accuracy: 0.4964 - val_loss: 0.6939 - val_accuracy: 0.4375\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6926 - accuracy: 0.5179 - val_loss: 0.6940 - val_accuracy: 0.4500\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6926 - accuracy: 0.5179 - val_loss: 0.6941 - val_accuracy: 0.4250\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6923 - accuracy: 0.5179 - val_loss: 0.6941 - val_accuracy: 0.4250\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.6919 - accuracy: 0.5107 - val_loss: 0.6941 - val_accuracy: 0.4250\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6911 - accuracy: 0.5179 - val_loss: 0.6930 - val_accuracy: 0.4125\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6893 - accuracy: 0.5357 - val_loss: 0.6902 - val_accuracy: 0.4375\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6862 - accuracy: 0.5964 - val_loss: 0.6855 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6830 - accuracy: 0.6429 - val_loss: 0.6779 - val_accuracy: 0.7875\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6758 - accuracy: 0.7357 - val_loss: 0.6695 - val_accuracy: 0.8375\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6631 - accuracy: 0.8036 - val_loss: 0.6554 - val_accuracy: 0.8500\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6529 - accuracy: 0.7500 - val_loss: 0.6317 - val_accuracy: 0.8750\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6285 - accuracy: 0.7786 - val_loss: 0.6009 - val_accuracy: 0.8875\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5931 - accuracy: 0.8107 - val_loss: 0.5628 - val_accuracy: 0.8875\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5682 - accuracy: 0.8179 - val_loss: 0.5224 - val_accuracy: 0.8875\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5264 - accuracy: 0.8357 - val_loss: 0.4783 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4771 - accuracy: 0.8571 - val_loss: 0.4323 - val_accuracy: 0.8750\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4463 - accuracy: 0.8607 - val_loss: 0.4031 - val_accuracy: 0.8375\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4125 - accuracy: 0.8393 - val_loss: 0.3651 - val_accuracy: 0.8750\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3662 - accuracy: 0.8964 - val_loss: 0.3652 - val_accuracy: 0.9000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3718 - accuracy: 0.8893 - val_loss: 0.3556 - val_accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3365 - accuracy: 0.8964 - val_loss: 0.3499 - val_accuracy: 0.8750\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3306 - accuracy: 0.8750 - val_loss: 0.3397 - val_accuracy: 0.8750\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2826 - accuracy: 0.9179 - val_loss: 0.3578 - val_accuracy: 0.8875\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2839 - accuracy: 0.9107 - val_loss: 0.3448 - val_accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2549 - accuracy: 0.9071 - val_loss: 0.3272 - val_accuracy: 0.8875\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3189 - accuracy: 0.8929 - val_loss: 0.3412 - val_accuracy: 0.9000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2635 - accuracy: 0.9214 - val_loss: 0.3499 - val_accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2697 - accuracy: 0.9000 - val_loss: 0.3372 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2560 - accuracy: 0.9143 - val_loss: 0.3114 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2608 - accuracy: 0.9036 - val_loss: 0.2996 - val_accuracy: 0.9125\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2523 - accuracy: 0.9107 - val_loss: 0.3060 - val_accuracy: 0.9000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2493 - accuracy: 0.9143 - val_loss: 0.3173 - val_accuracy: 0.9000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2326 - accuracy: 0.9321 - val_loss: 0.3082 - val_accuracy: 0.9125\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.2546 - accuracy: 0.9071 - val_loss: 0.2988 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2211 - accuracy: 0.9357 - val_loss: 0.3246 - val_accuracy: 0.9000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2224 - accuracy: 0.9393 - val_loss: 0.3112 - val_accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2085 - accuracy: 0.9393 - val_loss: 0.2742 - val_accuracy: 0.8875\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2113 - accuracy: 0.9214 - val_loss: 0.2528 - val_accuracy: 0.9000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2123 - accuracy: 0.9321 - val_loss: 0.2641 - val_accuracy: 0.9250\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2141 - accuracy: 0.9321 - val_loss: 0.2871 - val_accuracy: 0.9125\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2257 - accuracy: 0.9107 - val_loss: 0.2822 - val_accuracy: 0.8875\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2094 - accuracy: 0.9321 - val_loss: 0.2755 - val_accuracy: 0.9125\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2073 - accuracy: 0.9357 - val_loss: 0.2552 - val_accuracy: 0.9125\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2073 - accuracy: 0.9357 - val_loss: 0.2596 - val_accuracy: 0.9125\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1864 - accuracy: 0.9321 - val_loss: 0.3172 - val_accuracy: 0.9125\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1959 - accuracy: 0.9214 - val_loss: 0.3252 - val_accuracy: 0.9250\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2084 - accuracy: 0.9286 - val_loss: 0.3387 - val_accuracy: 0.9250\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1957 - accuracy: 0.9179 - val_loss: 0.3452 - val_accuracy: 0.9125\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1779 - accuracy: 0.9286 - val_loss: 0.3314 - val_accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "history = init_model().fit(x_train, Y_train, epochs=50, batch_size=64, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c97b86",
   "metadata": {},
   "source": [
    "Graph of Train and Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c4385cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.savefig(\"DeepFig.pdf\",dpi=1200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
